{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de696a1-79b5-461d-8556-9d3c201c0e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from pymongo.mongo_client import MongoClient\n",
    "import pandas\n",
    "import json\n",
    "import random\n",
    "import tqdm as tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a092884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "uri = st.secrets[\"mongo\"]['uri']\n",
    "client = MongoClient(uri)\n",
    "db = client[\"Replication\"]\n",
    "collexp_code = db.exp_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c953d890-8896-4dfd-9cad-450e90bd0d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nparticipants = 300\n",
    "\n",
    "BIAS = True\n",
    "\n",
    "biased = [0.5, 0.16, 0.16, 0.16] #biased\n",
    "unbiased = [0.25, 0.25, 0.25, 0.25] #biased\n",
    "\n",
    "cognitive_load_lower = 1\n",
    "cognitive_load_higher = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e12933a-4b92-4b0b-b4a4-774255e6b9b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prolific_id(length=24):\n",
    "    characters = string.ascii_uppercase + string.digits\n",
    "    prolific_id = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return prolific_id\n",
    "def generate_study_id(length=24):\n",
    "    characters = string.ascii_uppercase + string.digits\n",
    "    study_id = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return study_id\n",
    "def generate_session_id(length=24):\n",
    "    characters = string.ascii_uppercase + string.digits\n",
    "    session_id = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return session_id\n",
    "\n",
    "def generate_dummy_prolific_ids(count=10):\n",
    "    prolific_ids = [generate_prolific_id() for _ in range(count)]\n",
    "    return prolific_ids\n",
    "def generate_dummy_study_ids(count=10):\n",
    "    study_id = [generate_study_id() for _ in range(count)]\n",
    "    return study_id\n",
    "def generate_dummy_session_ids(count=10):\n",
    "    session_id = [generate_session_id() for _ in range(count)]\n",
    "    return session_id\n",
    "\n",
    "def write_prolific_ids_to_file(ids, filename='prolific_ids.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        for idx, pid in enumerate(ids, start=1):\n",
    "            file.write(f\"{pid}\\n\")\n",
    "            \n",
    "def write_study_ids_to_file(ids, filename='study_id.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        for idx, pid in enumerate(ids, start=1):\n",
    "            file.write(f\"{pid}\\n\")\n",
    "            \n",
    "def write_session_ids_to_file(ids, filename='session_id.txt'):\n",
    "    with open(filename, 'w') as file:\n",
    "        for idx, pid in enumerate(ids, start=1):\n",
    "            file.write(f\"{pid}\\n\")\n",
    "\n",
    "# write_prolific_ids_to_file(generate_dummy_prolific_ids(nparticipants))\n",
    "# write_study_ids_to_file(generate_dummy_study_ids(nparticipants))\n",
    "# write_session_ids_to_file(generate_dummy_session_ids(nparticipants))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95881a2e-67d9-4cb7-a99c-66eaaccceca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('prolific_ids.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    prolific_ids = file.read().split()\n",
    "    \n",
    "with open('study_id.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    study_ids = file.read().split()\n",
    "    \n",
    "with open('session_id.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    session_ids = file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eac0035-de91-4335-b669-f9ccda35d799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def updateRecord(key, value, newValue):\n",
    "    criteria = {key: value }\n",
    "    update_operation = {\"$set\": {key: newValue}}\n",
    "    return collexp_code.update_one(criteria, update_operation, upsert=False)\n",
    "\n",
    "def getExpCode(value_to_find = 'EMPTY'):\n",
    "\n",
    "    # The specific value you're looking for\n",
    "\n",
    "    def contains_value(doc, value):\n",
    "        # Recursively check if any field in the document contains the value\n",
    "        if isinstance(doc, dict):\n",
    "            for key, val in doc.items():\n",
    "                if contains_value(val, value):\n",
    "                    return True\n",
    "        elif isinstance(doc, list):\n",
    "            for item in doc:\n",
    "                if contains_value(item, value):\n",
    "                    return True\n",
    "        else:\n",
    "            return doc == value\n",
    "        return False\n",
    "\n",
    "    # Iterate over all documents in the collection\n",
    "    for doc in collexp_code.find():\n",
    "        if contains_value(doc, value_to_find):\n",
    "            return list(doc)[1]\n",
    "    else:\n",
    "        return -1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbca68eb-b641-4c1f-a9cf-a85d33f077d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getAlternative(weights = [0.25, 0.25, 0.25, 0.25], sqcondition = \"NEUT\"):\n",
    "    # Define the list of alternatives\n",
    "    alternatives = ['a', 'b', 'c', 'd']\n",
    "\n",
    "    # Perform biased random selection\n",
    "    selected_alternative = random.choices(alternatives, weights=weights, k=1)[0]\n",
    "\n",
    "    \n",
    "    # if sqcondition == \"SQ2\":\n",
    "    #     if selected_alternative == 'a':\n",
    "    #         selected_alternative = 'b'\n",
    "    #     elif selected_alternative == 'b':\n",
    "    #         selected_alternative = 'a'\n",
    "    # if sqcondition == \"SQ3\":\n",
    "    #     if selected_alternative == 'a':\n",
    "    #         selected_alternative = 'c'\n",
    "    #     elif selected_alternative == 'c':\n",
    "    #         selected_alternative = 'a'\n",
    "    # if sqcondition == \"SQ4\":\n",
    "    #     if selected_alternative == 'a':\n",
    "    #         selected_alternative = 'd'\n",
    "    #     elif selected_alternative == 'd':\n",
    "    #         selected_alternative = 'a'\n",
    "\n",
    "    return selected_alternative\n",
    "\n",
    "\n",
    "def chatdata(expcode, data):\n",
    "    expcode_1 = str(expcode).split('_')[1].split('&')[0].replace(\"$\", \"_\")\n",
    "    expcode_2 = str(expcode).split('_')[1].split('&')[1].replace(\"$\", \"_\")\n",
    "    expcode_3 = str(expcode).split('_')[1].split('&')[2].replace(\"$\", \"_\")\n",
    "\n",
    "\n",
    "    f = open(f\"../utterances/{expcode_1}.txt\", \"r\")\n",
    "    chat1_utterances = f.read().split(\"\\n\")\n",
    "    \n",
    "    f = open(f\"../utterances/{expcode_2}.txt\", \"r\")\n",
    "    chat2_utterances = f.read().split(\"\\n\")\n",
    "    \n",
    "    f = open(f\"../utterances/{expcode_3}.txt\", \"r\")\n",
    "    chat3_utterances = f.read().split(\"\\n\")\n",
    "    \n",
    "    counter = 0 \n",
    "    for i, obj in enumerate(data['chat1']): \n",
    "        if obj['role'] == 'assistant' and counter < len(chat1_utterances):\n",
    "            data['chat1'][i]['content'] = chat1_utterances[counter]\n",
    "            counter+=1\n",
    "    counter = 0 \n",
    "    for i, obj in enumerate(data['chat2']): \n",
    "        if obj['role'] == 'assistant' and counter < len(chat2_utterances):\n",
    "            data['chat2'][i]['content'] = chat2_utterances[counter]\n",
    "            counter+=1\n",
    "    counter = 0 \n",
    "    for i, obj in enumerate(data['chat3']): \n",
    "        if obj['role'] == 'assistant' and counter < len(chat3_utterances):\n",
    "            data['chat3'][i]['content'] = chat3_utterances[counter]\n",
    "            counter+=1\n",
    "            \n",
    "    #if neut condition generate at random\n",
    "    #if sqb condition generate biased\n",
    "            \n",
    "    for i, obj in enumerate(data['chat1']): \n",
    "        if obj['role'] == 'user' and i == len(data['chat1'])-2:\n",
    "            if expcode_1.find(\"NEUT\") > 0:\n",
    "                data['chat1'][i]['content'] = getAlternative(unbiased) #random\n",
    "            else:\n",
    "                if BIAS:\n",
    "                    data['chat1'][i]['content'] =  getAlternative(biased, expcode_1.split('_')[1]) #bias\n",
    "                else:\n",
    "                    data['chat1'][i]['content'] = getAlternative(unbiased) #random\n",
    "    \n",
    "    for i, obj in enumerate(data['chat2']): \n",
    "        if obj['role'] == 'user' and i == len(data['chat2'])-2:\n",
    "            if expcode_2.find(\"NEUT\") > 0:\n",
    "                data['chat2'][i]['content'] = getAlternative(unbiased) #random\n",
    "            else:\n",
    "                if BIAS:\n",
    "                    data['chat2'][i]['content'] =  getAlternative(biased, expcode_2.split('_')[1]) #bias\n",
    "                else:\n",
    "                    data['chat2'][i]['content'] = getAlternative(unbiased) #random           \n",
    "    \n",
    "    for i, obj in enumerate(data['chat3']): \n",
    "        if obj['role'] == 'user' and i == len(data['chat3'])-2:\n",
    "            if expcode_3.find(\"NEUT\") > 0:\n",
    "                data['chat3'][i]['content'] = getAlternative(unbiased) #random\n",
    "            else:\n",
    "                if BIAS:\n",
    "                    data['chat3'][i]['content'] =  getAlternative(biased, expcode_3.split('_')[1]) #bias\n",
    "                else:\n",
    "                    data['chat3'][i]['content'] = getAlternative(unbiased) #random\n",
    "                    \n",
    "    return data\n",
    "    \n",
    "\n",
    "def getData(prolific_pid, study_id, session_id, expcode, data):\n",
    "    data = chatdata(expcode, data)\n",
    "    data[\"prolific_pid\"] = prolific_pid\n",
    "    data[\"study_id\"] = study_id\n",
    "    data[\"session_id\"] = session_id\n",
    "    data[\"consent\"] = True\n",
    "    data[\"expcode\"] = expcode\n",
    "    # data[\"chat1\"] = chatdata()\n",
    "    # data[\"chat2\"] = chatdata()\n",
    "    # data[\"chat3\"] = chatdata()\n",
    "    data[\"ntlx1\"] = {\"Mental Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Physical Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Temporal Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Performance\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Effort\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Frustration\" : random.randint(cognitive_load_lower, cognitive_load_higher)}\n",
    "    data[\"ntlx2\"] = {\"Mental Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Physical Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Temporal Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Performance\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Effort\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Frustration\" : random.randint(cognitive_load_lower, cognitive_load_higher)}\n",
    "    data[\"ntlx3\"] = {\"Mental Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Physical Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Temporal Demand\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Performance\" : random.randint(cognitive_load_lower, cognitive_load_higher),\n",
    "                     \"Effort\" : random.randint(cognitive_load_lower, cognitive_load_higher), \"Frustration\" : random.randint(cognitive_load_lower, cognitive_load_higher)}\n",
    "    data[\"ac1\"] = True\n",
    "    data[\"ac2\"] = True\n",
    "    data[\"ac3\"] = True\n",
    "    data[\"serious\"] = \"7\"\n",
    "    return json.dumps(data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b8d410-c016-48e9-87c8-714b159f76e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [17:01<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(0, nparticipants)):\n",
    "    expcode = getExpCode()\n",
    "    tdata = getData(prolific_ids[i], study_ids[i], session_ids[i], expcode, data)\n",
    "    updateRecord(expcode, \"EMPTY\" , tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5fc7f-e579-48c3-87df-9b4c4be5de83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
